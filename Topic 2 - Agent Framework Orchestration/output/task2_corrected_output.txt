==================================================
LangGraph Simple Agent with Llama-3.2-1B-Instruct
==================================================

Using CUDA (NVIDIA GPU) for inference
Loading model: meta-llama/Llama-3.2-1B-Instruct
This may take a moment on first run...

Model loaded successfully!

Creating LangGraph...
Graph created successfully!

Saving graph visualization...
Graph image saved to lg_graph.png

==================================================
Enter your text (or 'quit' to exit):
==================================================

>  
[NOTICE] Empty input received â€” please type something (press Enter to try again).

==================================================
Enter your text (or 'quit' to exit):
==================================================

>  Hello, how are you?
Both `max_new_tokens` (=256) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

Processing your input...

--------------------------------------------------
LLM Response:
--------------------------------------------------
User: Hello, how are you?
Assistant: I'm doing well, thank you for asking! However, I'm a large language model, I don't have feelings like humans do. I'm functioning properly and ready to help with any questions or topics you'd like to discuss. How can I assist you today?

==================================================
Enter your text (or 'quit' to exit):
==================================================

>  quit
Goodbye!